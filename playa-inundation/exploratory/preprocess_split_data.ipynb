{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load att df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playa_att_csv_path = '../data/playa_nogeometry_whucs.csv'\n",
    "playa_att_df = pd.read_csv(playa_att_csv_path).set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert HUC and author to int codes: (using huc8 instead of huc12)\n",
    "playa_att_df['huc8'] = playa_att_df['huc12'].astype(str).str[0:8]\n",
    "playa_att_df['huc8'] = playa_att_df['huc8'].astype('category').cat.codes\n",
    "\n",
    "playa_att_df['author'] = playa_att_df['author'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate lookup tables for HUC code (using HUC8)\n",
    "# playa_att_df['huc8'] = playa_att_df['huc12'].astype(str).str[0:8]\n",
    "# huc8_ascat = playa_att_df['huc8'].astype(int).astype('category')\n",
    "# cats = huc8_ascat.cat.categories\n",
    "# codes = huc8_ascat.cat.codes.unique().tolist()\n",
    "# huc_dict = dict(zip(cats,codes))\n",
    "# with open('huc_lut.json', 'w') as fp:\n",
    "#     json.dump(huc_dict, fp)\n",
    "    \n",
    "# # Calculate lookup tables for author string\n",
    "# author_ascat = playa_att_df['author'].astype('category')\n",
    "# cats = author_ascat.cat.categories\n",
    "# codes = author_ascat.cat.codes.unique().tolist()\n",
    "# author_dict = dict(zip(cats,codes))\n",
    "# with open('author_lut.json', 'w') as fp:\n",
    "#     json.dump(author_dict, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess data to split up by state and county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inun_csv_path = '../data/jrc-water_1984-2019.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inun_df = pd.read_csv(inun_csv_path).set_index('id').drop('.geo', axis=1).rename(columns={'mean':'inundation'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_state_county_csvs_inun(state, inun_df, playa_att_df):\n",
    "    # Join state and county\n",
    "    state_df = inun_df.join(playa_att_df.loc[playa_att_df['state']==state,\n",
    "                                             ['state', 'countyfips', 'acres','huc8', 'winddevyr',\n",
    "                                              'author','meanwetfrq','cluster','healthy','farmed','hydromod',\n",
    "                                              'fttoroad', 'sthick2013']\n",
    "                                            ]\n",
    "                            ,how='inner')\n",
    "    \n",
    "    # Split up weird index into year + months\n",
    "    split_index = state_df['system:index'].str.split('_', expand=True)\n",
    "    state_df = state_df.assign(year=split_index[0].astype('int16'),\n",
    "                               month=split_index[1].astype('int16'),\n",
    "                               area=state_df['acres']*state_df['inundation'])\n",
    "    state_df.drop(['system:index', 'state'], axis=1, inplace=True)\n",
    "    \n",
    "    # Save state csv\n",
    "    state_out_path = '../data/state_county_csvs/inun_frac_{}.csv'.format(state)\n",
    "    state_df.drop('countyfips', axis=1).to_csv(state_out_path)\n",
    "    \n",
    "    # Save county csvs\n",
    "    for county in state_df['countyfips'].unique():\n",
    "        county_df = state_df.loc[state_df['countyfips']==county]\n",
    "        county_out_path = '../data/state_county_csvs/counties/inun_frac_{}_{}.csv'.format(state, county)\n",
    "        county_df.drop('countyfips', axis=1).to_csv(county_out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save state and county csvs\n",
    "for state in playa_att_df['state'].unique():\n",
    "    save_state_county_csvs_inun(state, inun_df, playa_att_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess and split weather data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prism data (current version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_csv_path = '../data/prism.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = pd.read_csv(weather_csv_path).set_index('id').drop('.geo', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_state_county_csvs_weather(state, weather_df, playa_att_df):\n",
    "    # Join state and county\n",
    "    state_df = weather_df.join(playa_att_df.loc[playa_att_df['state']==state,\n",
    "                                             ['state', 'countyfips']],how='inner')\n",
    "    \n",
    "    # Split up weird index into year + months, little different than inundation\n",
    "    state_df = state_df.assign(year=state_df['system:index'].str.slice(0,4).astype('int16'),\n",
    "                               month=state_df['system:index'].str.slice(4,6).astype('int16'))\n",
    "    state_df.drop(['system:index', 'state'], axis=1, inplace=True)\n",
    "    \n",
    "    # Rename to simpler column names\n",
    "    state_df = state_df.rename(columns={'tmean':'temp', 'ppt':'precip', 'vpdmin':'vpd'})\n",
    "    \n",
    "    # Save state csv\n",
    "    state_out_path = '../data/state_county_csvs/weather_{}.csv'.format(state)\n",
    "    state_df.drop('countyfips', axis=1).to_csv(state_out_path)\n",
    "    \n",
    "    # Save county csvs\n",
    "    for county in state_df['countyfips'].unique():\n",
    "        county_df = state_df.loc[state_df['countyfips']==county]\n",
    "        county_out_path = '../data/state_county_csvs/counties/weather_{}_{}.csv'.format(state, county)\n",
    "        county_df.drop('countyfips', axis=1).to_csv(county_out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save state and county csvs\n",
    "for state in playa_att_df['state'].unique():\n",
    "    save_state_county_csvs_weather(state, weather_df, playa_att_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Era Data (outdated, using prism now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weather_csv_path = '../data/era5_1984-2019.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weather_df = pd.read_csv(weather_csv_path).set_index('id').drop('.geo', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save state and county csvs\n",
    "# for state in playa_att_df['state'].unique():\n",
    "    \n",
    "#     # Join state and county\n",
    "#     state_df = weather_df.join(playa_att_df.loc[playa_att_df['state']==state,\n",
    "#                                              ['state', 'countyfips']],how='inner')\n",
    "    \n",
    "#     # Split up weird index into year + months, little different than inundation\n",
    "#     state_df = state_df.assign(year=state_df['system:index'].str.slice(0,4).astype('int16'),\n",
    "#                                month=state_df['system:index'].str.slice(4,6).astype('int16'))\n",
    "#     state_df.drop(['system:index', 'state'], axis=1, inplace=True)\n",
    "    \n",
    "#     # Rename to simpler column names\n",
    "#     state_df = state_df.rename(columns={'mean_2m_air_temperature':'temp', 'total_precipitation':'precip'})\n",
    "    \n",
    "#     # Save state csv\n",
    "#     state_out_path = '../data/state_county_csvs/weather_{}.csv'.format(state)\n",
    "#     state_df.drop('countyfips', axis=1).to_csv(state_out_path)\n",
    "    \n",
    "#     # Save county csvs\n",
    "#     for county in state_df['countyfips'].unique():\n",
    "#         county_df = state_df.loc[state_df['countyfips']==county]\n",
    "#         county_out_path = '../data/state_county_csvs/counties/weather_{}_{}.csv'.format(state, county)\n",
    "#         county_df.drop('countyfips', axis=1).to_csv(county_out_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "playa_venv",
   "language": "python",
   "name": "playa_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
