{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import log_loss, f1_score, roc_curve, precision_score, recall_score, accuracy_score, auc\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playa_att_df = pd.read_csv('../data/playa_nogeometry_whucs.csv')\n",
    "playa_att_df = playa_att_df.set_index('id')\n",
    "playa_att_df = playa_att_df[['state','acres','countyfips','cluster','farmed','hydromod','healthy', 'huc12', 'author']]\n",
    "playa_att_df['huc4'] = playa_att_df['huc12'].astype(str).str[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precip_df = pd.read_csv('../data/prism.csv', usecols=['id','ppt', 'system:index']).rename(columns={'ppt':'precip'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precip_df['year'] = precip_df['system:index'].str.slice(0,4).astype('int16')\n",
    "precip_df['month'] = precip_df['system:index'].str.slice(4,6).astype('int16')\n",
    "precip_df['day'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precip_df['date'] = pd.to_datetime(precip_df[['year','month', 'day']])\n",
    "precip_df = precip_df.loc[precip_df['date']>=pd.Timestamp('1984-03-01')]\n",
    "precip_df = precip_df.set_index(['id','date']).drop(columns=['year','month','day','system:index'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.read_csv('../data/all_preds_best_mean_inun_v2_calibrated.csv')\n",
    "pred_df['pred'] = pred_df['pred_cal'] # for calibrated results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add months and years back in\n",
    "pred_df['date'] = np.tile(pd.date_range('1984-03', periods=418, freq='M'), int(pred_df.shape[0]/418))\n",
    "pred_df = pred_df.set_index(['id','date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary statistics of attributes (non-modeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acres to ha\n",
    "playa_att_df['ha'] = playa_att_df['acres']*0.40469\n",
    "print('Fraction farmed: ', playa_att_df['farmed'].mean())\n",
    "print('Fraction modified: ', playa_att_df['hydromod'].mean())\n",
    "print('Mean Size :', playa_att_df['ha'].mean())\n",
    "print('Median Size :', playa_att_df['ha'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "att_pred_df = pred_df.reset_index().groupby('id').max().join(playa_att_df, how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('never inundated, smaller than median:',1-att_pred_df.loc[att_pred_df['acres']<2.6955850000000003, 'true'].mean())\n",
    "print('never inundated, larger than median:', 1-att_pred_df.loc[att_pred_df['acres']>2.6955850000000003, 'true'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Fraction smaller than 1 ha:', (att_pred_df['ha']<1).mean())\n",
    "print('Fraction smaller than 0.5 ha:', (att_pred_df['ha']<0.5).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "northern_att_pred_df = att_pred_df.loc[att_pred_df['state'].isin(['KS', 'NB', 'CO'])]\n",
    "print('northern states, farmed:', northern_att_pred_df['farmed'].mean())\n",
    "print('northern states, median size:', northern_att_pred_df['ha'].median())\n",
    "print('northern states, not inundated fraction:', 1-northern_att_pred_df['true'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_f1_score(true, pred, cutoff=0.25):\n",
    "    return f1_score(true, pred>cutoff, zero_division=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df['set_flag'] = 2\n",
    "pred_df.loc[pred_df.index.get_level_values(1)<pd.Timestamp('2015-01-01'), 'set_flag'] = 1\n",
    "pred_df.loc[pred_df.index.get_level_values(1)<pd.Timestamp('2011-01-01'), 'set_flag'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pred_df.assign(pred_binary=pred_df['pred']>0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_df = pred_df.loc[pred_df['set_flag']==2]\n",
    "val_pred_df = pred_df.loc[pred_df['set_flag']==1]\n",
    "train_pred_df = pred_df.loc[pred_df['set_flag']==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic accuracy stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train Accuracy: ', accuracy_score(train_pred_df['true'], train_pred_df['pred_binary']))\n",
    "print('Train loss: ',log_loss(train_pred_df['true'], train_pred_df['pred']))\n",
    "print('Train Recall:', recall_score(train_pred_df['true'], train_pred_df['pred_binary']))\n",
    "print('Train Precision:', precision_score(train_pred_df['true'], train_pred_df['pred_binary']))\n",
    "print('Train F1:',calc_f1_score(train_pred_df['true'], train_pred_df['pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Val Accuracy: ', accuracy_score(val_pred_df['true'], val_pred_df['pred_binary']))\n",
    "print('Val loss: ',log_loss(val_pred_df['true'], val_pred_df['pred']))\n",
    "print('Val Recall:', recall_score(val_pred_df['true'], val_pred_df['pred_binary']))\n",
    "print('Val Precision:', precision_score(val_pred_df['true'], val_pred_df['pred_binary']))\n",
    "print('Val F1:',calc_f1_score(val_pred_df['true'], val_pred_df['pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test Accuracy: ', accuracy_score(test_pred_df['true'], test_pred_df['pred_binary']))\n",
    "print('Test loss: ', log_loss(test_pred_df['true'], test_pred_df['pred']))\n",
    "print('Test Recall:', recall_score(test_pred_df['true'], test_pred_df['pred_binary']))\n",
    "print('Test Precision:', precision_score(test_pred_df['true'], test_pred_df['pred_binary']))\n",
    "print('Test F1:',calc_f1_score(test_pred_df['true'], test_pred_df['pred']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline using random or all zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('All 0 Val Accuracy:', accuracy_score(val_pred_df['true'], np.zeros(val_pred_df['true'].shape)))\n",
    "print('All 0 Val Loss:', log_loss(val_pred_df['true'], np.zeros(val_pred_df['true'].shape)))\n",
    "rand_val = np.random.binomial(1, 0.5, val_pred_df['true'].shape)\n",
    "print('Random Val Accuracy:', accuracy_score(val_pred_df['true'], rand_val))\n",
    "print('Random Val Loss:', log_loss(val_pred_df['true'],rand_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('All 0 test Accuracy:', accuracy_score(test_pred_df['true'], np.zeros(test_pred_df['true'].shape)))\n",
    "print('All 0 test Loss:', log_loss(test_pred_df['true'], np.zeros(test_pred_df['true'].shape)))\n",
    "rand_test = np.random.binomial(1, 0.5, test_pred_df['true'].shape)\n",
    "print('Random test Accuracy:', accuracy_score(test_pred_df['true'], rand_test))\n",
    "print('Random test Loss:', log_loss(test_pred_df['true'],rand_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(train_pred_df['true'],train_pred_df['pred'])\n",
    "print('Train AUC: ', auc(fpr, tpr))\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Pos Rate', size=13)\n",
    "plt.ylabel('True Pos Rate', size=13)\n",
    "plt.plot([-1,2], [-1,2], 'k-', lw=1)\n",
    "plt.xlim([-0.02,1.02])\n",
    "plt.ylim([-0.02,1.02])\n",
    "plt.title('Train ROC', size=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(val_pred_df['true'],val_pred_df['pred'])\n",
    "print('Val AUC: ', auc(fpr, tpr))\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Pos Rate', size=13)\n",
    "plt.ylabel('True Pos Rate', size=13)\n",
    "plt.plot([-1,2], [-1,2], 'k-', lw=1)\n",
    "plt.xlim([-0.02,1.02])\n",
    "plt.ylim([-0.02,1.02])\n",
    "plt.title('Val ROC', size=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(test_pred_df['true'], test_pred_df['pred'])\n",
    "print('Test AUC: ', auc(fpr, tpr))\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Pos Rate', size=13)\n",
    "plt.ylabel('True Pos Rate',size=13)\n",
    "plt.plot([-1,2], [-1,2], 'k-', lw=1)\n",
    "plt.xlim([-0.02,1.02])\n",
    "plt.ylim([-0.02,1.02])\n",
    "plt.title('Test ROC', size=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paper Figure: Test and Val together\n",
    "# Val\n",
    "fig, ax = plt.subplots(1,2,figsize=(12,4))\n",
    "fpr, tpr, thresholds = roc_curve(val_pred_df['true'],val_pred_df['pred'])\n",
    "ax[0].plot(fpr, tpr)\n",
    "ax[0].set_xlabel('False Pos Rate', size=13)\n",
    "ax[0].set_ylabel('True Pos Rate',size=13)\n",
    "ax[0].plot([-1,2], [-1,2], 'k-', lw=1)\n",
    "ax[0].set_xlim([-0.02,1.02])\n",
    "ax[0].set_ylim([-0.02,1.02])\n",
    "ax[0].set_title('Val ROC', size=14)\n",
    "# Test\n",
    "fpr, tpr, thresholds = roc_curve(test_pred_df['true'], test_pred_df['pred'])\n",
    "ax[1].plot(fpr, tpr)\n",
    "ax[1].set_xlabel('False Pos Rate', size=13)\n",
    "ax[1].set_ylabel('True Pos Rate',size=13)\n",
    "ax[1].plot([-1,2], [-1,2], 'k-', lw=1)\n",
    "ax[1].set_xlim([-0.02,1.02])\n",
    "ax[1].set_ylim([-0.02,1.02])\n",
    "ax[1].set_title('Test ROC', size=14)\n",
    "plt.savefig('/home/ksolvik/research/misc_projects/playa/deliverables/figures/val_test_roc.png', dpi=300, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error analysis broken down by playa size and other atts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_df_atts = test_pred_df.reset_index().merge(playa_att_df[['acres','farmed', 'hydromod']].reset_index(), on='id').set_index(['id','date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size quantiles\n",
    "print(np.quantile(playa_att_df['acres'], 0.25))\n",
    "print(np.quantile(playa_att_df['acres'], 0.5))\n",
    "print(np.quantile(playa_att_df['acres'], 0.75))\n",
    "size_first_q = np.quantile(playa_att_df['acres'], 0.25)\n",
    "size_second_q = np.quantile(playa_att_df['acres'], 0.5)\n",
    "size_third_q = np.quantile(playa_att_df['acres'], 0.75)\n",
    "test_pred_size_first_q = test_pred_df_atts.loc[test_pred_df_atts['acres']<size_first_q]\n",
    "test_pred_size_second_q = test_pred_df_atts.loc[(test_pred_df_atts['acres']>size_first_q) & (test_pred_df_atts['acres']<size_second_q)]\n",
    "test_pred_size_third_q = test_pred_df_atts.loc[(test_pred_df_atts['acres']>size_second_q) & (test_pred_df_atts['acres']<size_third_q)]\n",
    "test_pred_size_fourth_q = test_pred_df_atts.loc[test_pred_df_atts['acres']>size_third_q]\n",
    "test_pred_size_bigger = test_pred_df_atts.loc[test_pred_df_atts['acres']>size_second_q]\n",
    "test_pred_size_smaller = test_pred_df_atts.loc[test_pred_df_atts['acres']<size_second_q]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('first_q Size Test Accuracy: ', accuracy_score(test_pred_size_first_q['true'], test_pred_size_first_q['pred_binary']))\n",
    "print('first_q Size Test loss: ', log_loss(test_pred_size_first_q['true'], test_pred_size_first_q['pred']))\n",
    "print('first_q Size Test Recall:', recall_score(test_pred_size_first_q['true'], test_pred_size_first_q['pred_binary']))\n",
    "print('first_q Size Test Precision:', precision_score(test_pred_size_first_q['true'], test_pred_size_first_q['pred_binary']))\n",
    "print('first_q Size Test F1:',calc_f1_score(test_pred_size_first_q['true'], test_pred_size_first_q['pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('second_q Size Test Accuracy: ', accuracy_score(test_pred_size_second_q['true'], test_pred_size_second_q['pred_binary']))\n",
    "print('second_q Size Test loss: ', log_loss(test_pred_size_second_q['true'], test_pred_size_second_q['pred']))\n",
    "print('second_q Size Test Recall:', recall_score(test_pred_size_second_q['true'], test_pred_size_second_q['pred_binary']))\n",
    "print('second_q Size Test Precision:', precision_score(test_pred_size_second_q['true'], test_pred_size_second_q['pred_binary']))\n",
    "print('second_q Size Test F1:',calc_f1_score(test_pred_size_second_q['true'], test_pred_size_second_q['pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('third_q Size Test Accuracy: ', accuracy_score(test_pred_size_third_q['true'], test_pred_size_third_q['pred_binary']))\n",
    "print('third_q Size Test loss: ', log_loss(test_pred_size_third_q['true'], test_pred_size_third_q['pred']))\n",
    "print('third_q Size Test Recall:', recall_score(test_pred_size_third_q['true'], test_pred_size_third_q['pred_binary']))\n",
    "print('third_q Size Test Precision:', precision_score(test_pred_size_third_q['true'], test_pred_size_third_q['pred_binary']))\n",
    "print('third_q Size Test F1:',calc_f1_score(test_pred_size_third_q['true'], test_pred_size_third_q['pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('fourth_q Size Test Accuracy: ', accuracy_score(test_pred_size_fourth_q['true'], test_pred_size_fourth_q['pred_binary']))\n",
    "print('fourth_q Size Test loss: ', log_loss(test_pred_size_fourth_q['true'], test_pred_size_fourth_q['pred']))\n",
    "print('fourth_q Size Test Recall:', recall_score(test_pred_size_fourth_q['true'], test_pred_size_fourth_q['pred_binary']))\n",
    "print('fourth_q Size Test Precision:', precision_score(test_pred_size_fourth_q['true'], test_pred_size_fourth_q['pred_binary']))\n",
    "print('fourth_q Size Test F1:',calc_f1_score(test_pred_size_fourth_q['true'], test_pred_size_fourth_q['pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('bigger Size Test Accuracy: ', accuracy_score(test_pred_size_bigger['true'], test_pred_size_bigger['pred_binary']))\n",
    "print('bigger Size Test loss: ', log_loss(test_pred_size_bigger['true'], test_pred_size_bigger['pred']))\n",
    "print('bigger Size Test Recall:', recall_score(test_pred_size_bigger['true'], test_pred_size_bigger['pred_binary']))\n",
    "print('bigger Size Test Precision:', precision_score(test_pred_size_bigger['true'], test_pred_size_bigger['pred_binary']))\n",
    "print('bigger Size Test F1:',calc_f1_score(test_pred_size_bigger['true'], test_pred_size_bigger['pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('smaller Size Test Accuracy: ', accuracy_score(test_pred_size_smaller['true'], test_pred_size_smaller['pred_binary']))\n",
    "print('smaller Size Test loss: ', log_loss(test_pred_size_smaller['true'], test_pred_size_smaller['pred']))\n",
    "print('smaller Size Test Recall:', recall_score(test_pred_size_smaller['true'], test_pred_size_smaller['pred_binary']))\n",
    "print('smaller Size Test Precision:', precision_score(test_pred_size_smaller['true'], test_pred_size_smaller['pred_binary']))\n",
    "print('smaller Size Test F1:',calc_f1_score(test_pred_size_smaller['true'], test_pred_size_smaller['pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Farmed vs not farmed\n",
    "test_pred_farmed = test_pred_df_atts.loc[test_pred_df_atts['farmed']==1]\n",
    "test_pred_unfarmed = test_pred_df_atts.loc[test_pred_df_atts['farmed']==0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('farmed Size Test Accuracy: ', accuracy_score(test_pred_farmed['true'], test_pred_farmed['pred_binary']))\n",
    "print('farmed Size Test loss: ', log_loss(test_pred_farmed['true'], test_pred_farmed['pred']))\n",
    "print('farmed Size Test Recall:', recall_score(test_pred_farmed['true'], test_pred_farmed['pred_binary']))\n",
    "print('farmed Size Test Precision:', precision_score(test_pred_farmed['true'], test_pred_farmed['pred_binary']))\n",
    "print('farmed Size Test F1:',calc_f1_score(test_pred_farmed['true'], test_pred_farmed['pred']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('unfarmed Size Test Accuracy: ', accuracy_score(test_pred_unfarmed['true'], test_pred_unfarmed['pred_binary']))\n",
    "print('unfarmed Size Test loss: ', log_loss(test_pred_unfarmed['true'], test_pred_unfarmed['pred']))\n",
    "print('unfarmed Size Test Recall:', recall_score(test_pred_unfarmed['true'], test_pred_unfarmed['pred_binary']))\n",
    "print('unfarmed Size Test Precision:', precision_score(test_pred_unfarmed['true'], test_pred_unfarmed['pred_binary']))\n",
    "print('unfarmed Size Test F1:',calc_f1_score(test_pred_unfarmed['true'], test_pred_unfarmed['pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mofidied vs not\n",
    "test_pred_mod = test_pred_df_atts.loc[test_pred_df_atts['hydromod']==1]\n",
    "test_pred_unmod = test_pred_df_atts.loc[test_pred_df_atts['hydromod']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('mod Size Test Accuracy: ', accuracy_score(test_pred_mod['true'], test_pred_mod['pred_binary']))\n",
    "print('mod Size Test loss: ', log_loss(test_pred_mod['true'], test_pred_mod['pred']))\n",
    "print('mod Size Test Recall:', recall_score(test_pred_mod['true'], test_pred_mod['pred_binary']))\n",
    "print('mod Size Test Precision:', precision_score(test_pred_mod['true'], test_pred_mod['pred_binary']))\n",
    "print('mod Size Test F1:',calc_f1_score(test_pred_mod['true'], test_pred_mod['pred']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('unmod Size Test Accuracy: ', accuracy_score(test_pred_unmod['true'], test_pred_unmod['pred_binary']))\n",
    "print('unmod Size Test loss: ', log_loss(test_pred_unmod['true'], test_pred_unmod['pred']))\n",
    "print('unmod Size Test Recall:', recall_score(test_pred_unmod['true'], test_pred_unmod['pred_binary']))\n",
    "print('unmod Size Test Precision:', precision_score(test_pred_unmod['true'], test_pred_unmod['pred_binary']))\n",
    "print('unmod Size Test F1:',calc_f1_score(test_pred_unmod['true'], test_pred_unmod['pred']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate loss per playa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot best, worst, and a few in the middle\n",
    "def plot_single_playa_trajectory(df, id, ax=None, wide=False):\n",
    "    playa_df = df.loc[id]\n",
    "    if ax==None:\n",
    "        if wide:\n",
    "            playa_df[['true','pred']].plot(figsize=[15,2.2])\n",
    "            plt.text(dt.datetime(2011,3,1), 1.05, 'Validation', size=14)\n",
    "            plt.text(dt.datetime(2015,3,1), 1.05, 'Test', size=14)\n",
    "            plt.text(dt.datetime(1984,3,1), 1.05, 'Train', size=14)\n",
    "        else:\n",
    "            playa_df[['true','pred']].plot(figsize=[15,4])\n",
    "            plt.text(dt.datetime(2011,3,1), 1.1, 'Validation', size=14)\n",
    "            plt.text(dt.datetime(2015,3,1), 1.1, 'Test', size=14)\n",
    "            plt.text(dt.datetime(1984,3,1), 1.1, 'Train', size=14)\n",
    "    else:\n",
    "        playa_df[['true','pred']].plot(ax=ax, legend=False)\n",
    "        ax.text(dt.datetime(2011,3,1), 1.05, 'Validation', size=14)\n",
    "        ax.text(dt.datetime(2015,3,1), 1.05, 'Test', size=14)\n",
    "        ax.text(dt.datetime(1984,3,1), 1.05, 'Train', size=14)\n",
    "    ax.set_ylim(-0.025,1.025)\n",
    "    ax.set_xlabel('Date', size=13)\n",
    "    ax.set_ylabel('P(Inundation)', size=13)\n",
    "    ax.set_xlim(dt.datetime(1984,1,1), dt.datetime(2019,1,1))\n",
    "    ax.axvline(dt.datetime(2015,1,1), color='black')\n",
    "    ax.axvline(dt.datetime(2011,1,1), color='black')\n",
    "    #ax.text(dt.datetime(1984,3,1), 0.275, 'Threshold', size=11)\n",
    "    # ax.axhline(0.25, color='black', linestyle='--', linewidth=0.8)\n",
    "\n",
    "    if ax==None:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_precip_trajectory(df, id):\n",
    "    precip_df = df.loc[id]\n",
    "    precip_df['precip'].plot(figsize=[15,5])\n",
    "    plt.axvline(dt.datetime(2015,1,1), color='black')\n",
    "    plt.axvline(dt.datetime(2011,1,1), color='black')\n",
    "    plt.text(dt.datetime(2011,3,1), 1.1, 'Validation', size=14)\n",
    "    plt.text(dt.datetime(2015,3,1), 1.1, 'Test', size=14)\n",
    "    plt.text(dt.datetime(1984,3,1), 1.1, 'Train', size=14)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test loss only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_inun_test = test_pred_df.groupby('id').aggregate({'true':'max'})\n",
    "test_nonzero_ids = max_inun_test.index[max_inun_test['true'].values>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('../data/per_playa_test_loss_v2.csv'):# Looping to save some memory\n",
    "    per_loop = 5000\n",
    "    test_starts = np.arange(0, test_pred_df.shape[0], per_loop*48)\n",
    "    per_playa_test_loss_series = pd.Series(dtype='float64')\n",
    "    for start_point in test_starts:\n",
    "        end = min(pred_df.shape[0], start_point + per_loop*48)\n",
    "        temp_loss_series = test_pred_df.iloc[start_point:end].groupby('id').apply(lambda df: log_loss(df['true'],df['pred'], labels=[0,1]))\n",
    "        per_playa_test_loss_series = per_playa_test_loss_series.append(temp_loss_series)\n",
    "        \n",
    "    per_playa_test_loss_series.to_csv('../data/per_playa_test_loss_v2.csv')    \n",
    "else:\n",
    "    per_playa_test_loss_series = pd.read_csv('../data/per_playa_test_loss_v2.csv', names=['id','loss']).iloc[1:].set_index('id')['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_nonzero_per_playa_loss = per_playa_test_loss_series.loc[test_nonzero_ids].sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paper figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, figsize=(15,6.6))\n",
    "plot_single_playa_trajectory(pred_df,test_nonzero_per_playa_loss.index[1], ax=axs[0])\n",
    "plot_single_playa_trajectory(pred_df, test_nonzero_per_playa_loss.index[int(test_nonzero_per_playa_loss.shape[0]/2)-1], ax=axs[1])\n",
    "plot_single_playa_trajectory(pred_df,test_nonzero_per_playa_loss.index[-1], ax=axs[2])\n",
    "axs[2].legend(['True','Predicted'], loc=9, prop={'size':12})\n",
    "axs[0].text(dt.datetime(1984,3,1), 0.86, '(a)', size=13)\n",
    "axs[1].text(dt.datetime(1984,3,1), 0.86, '(b)', size=13)\n",
    "axs[2].text(dt.datetime(1984,3,1), 0.86, '(c)', size=13)\n",
    "plt.subplots_adjust(hspace = 0.35)\n",
    "plt.savefig('/home/ksolvik/research/misc_projects/playa/deliverables/figures/inun_record_goodmedian_bad.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Misc exploratory plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_single_playa_trajectory(pred_df,test_nonzero_per_playa_loss.index[0], wide=True)\n",
    "plot_precip_trajectory(precip_df, test_nonzero_per_playa_loss.index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_single_playa_trajectory(pred_df, test_nonzero_per_playa_loss.index[-1], wide=True)\n",
    "plot_precip_trajectory(precip_df, test_nonzero_per_playa_loss.index[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_single_playa_trajectory(pred_df, test_nonzero_per_playa_loss.index[int(test_nonzero_per_playa_loss.shape[0]/2)], wide=True)\n",
    "plot_single_playa_trajectory(pred_df, test_nonzero_per_playa_loss.index[int(test_nonzero_per_playa_loss.shape[0]/2)+1], wide=True)\n",
    "plot_single_playa_trajectory(pred_df, test_nonzero_per_playa_loss.index[int(test_nonzero_per_playa_loss.shape[0]/2)-1], wide=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('../data/per_playa_test_f1_v2.csv'):# Looping to save some memory\n",
    "    per_loop = 5000\n",
    "    test_starts = np.arange(0, test_pred_df.shape[0], per_loop*48)\n",
    "    per_playa_test_f1_series = pd.Series(dtype='float64')\n",
    "    for start_point in test_starts:\n",
    "        end = min(pred_df.shape[0], start_point + per_loop*48)\n",
    "        temp_f1_series = test_pred_df.iloc[start_point:end].groupby('id').apply(lambda df: calc_f1_score(df['true'],df['pred']))\n",
    "        per_playa_test_f1_series = per_playa_test_f1_series.append(temp_f1_series)\n",
    "        \n",
    "    per_playa_test_f1_series.to_csv('../data/per_playa_test_f1_v2.csv')    \n",
    "else:\n",
    "    per_playa_test_f1_series = pd.read_csv('../data/per_playa_test_f1_v2.csv', names=['id','f1']).iloc[1:].set_index('id')['f1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_inun = pred_df.groupby('id').aggregate({'true':'max'})\n",
    "nonzero_ids = max_inun.index[max_inun['true'].values>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(max_inun).to_csv('../data/max_inundation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('../data/per_playa_all_loss_v2.csv'):# Looping to save some memory\n",
    "   # Looping to save some memory\n",
    "    per_loop = 2000\n",
    "    starts = np.arange(0, pred_df.shape[0], per_loop*418)\n",
    "    per_playa_loss_series = pd.Series(dtype='float64')\n",
    "    for start_point in starts:\n",
    "        end = min(pred_df.shape[0], start_point + per_loop*418)\n",
    "        temp_loss_series = pred_df.iloc[start_point:end].groupby('id').apply(lambda df: log_loss(df['true'],df['pred'], labels=[0,1]))\n",
    "        per_playa_loss_series = per_playa_loss_series.append(temp_loss_series)\n",
    "        \n",
    "    per_playa_loss_series.to_csv('../data/per_playa_all_loss_v2.csv')    \n",
    "else:\n",
    "    per_playa_loss_series = pd.read_csv('../data/per_playa_all_loss_v2.csv', names=['id','loss']).iloc[1:].set_index('id')['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonzero_per_playa_loss = per_playa_loss_series.loc[nonzero_ids].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_single_playa_trajectory(pred_df,nonzero_per_playa_loss.index[0])\n",
    "plot_precip_trajectory(precip_df,nonzero_per_playa_loss.index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_single_playa_trajectory(pred_df, nonzero_per_playa_loss.index[-1])\n",
    "plot_precip_trajectory(precip_df,nonzero_per_playa_loss.index[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_single_playa_trajectory(pred_df, nonzero_per_playa_loss.index[int(nonzero_per_playa_loss.shape[0]/2)])\n",
    "plot_single_playa_trajectory(pred_df, nonzero_per_playa_loss.index[int(nonzero_per_playa_loss.shape[0]/2)+1])\n",
    "plot_single_playa_trajectory(pred_df, nonzero_per_playa_loss.index[int(nonzero_per_playa_loss.shape[0]/2)-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playa Inundation over time (predicted vs real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df[['true','pred_binary']].groupby('date').mean().plot(figsize=[15,5])\n",
    "plt.axvline(dt.datetime(2014,1,1), color='black')\n",
    "plt.axvline(dt.datetime(2010,1,1), color='black')\n",
    "plt.text(dt.datetime(2010,3,1), 0.14, 'Validation', size=15)\n",
    "plt.text(dt.datetime(2014,3,1), 0.14, 'Test', size=15)\n",
    "plt.text(dt.datetime(1984,5,1), 0.14, 'Train', size=15)\n",
    "plt.legend(['True','Predicted'], loc=9)\n",
    "plt.ylim([0,0.15])\n",
    "plt.show()\n",
    "\n",
    "precip_df[['precip']].groupby('date').mean().plot(figsize=[15,5])\n",
    "plt.axvline(dt.datetime(2014,1,1), color='black')\n",
    "plt.axvline(dt.datetime(2010,1,1), color='black')\n",
    "plt.text(dt.datetime(2010,3,1), -0.5, 'Validation', size=15)\n",
    "plt.text(dt.datetime(2014,3,1), -0.5, 'Test', size=15)\n",
    "plt.text(dt.datetime(1984,5,1), -0.5 'Train', size=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatial representation of val/test error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_df = test_pred_df.reset_index().set_index('id')\n",
    "val_pred_df = val_pred_df.reset_index().set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_df = test_pred_df.join(playa_att_df, how='inner')\n",
    "val_pred_df = val_pred_df.join(playa_att_df, how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By state to start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_test_loss = test_pred_df.groupby('state').apply(lambda df: log_loss(df['true'],df['pred'], labels=[0,1]))\n",
    "state_val_loss = val_pred_df.groupby('state').apply(lambda df: log_loss(df['true'],df['pred'], labels=[0,1]))\n",
    "state_test_f1 = test_pred_df.groupby('state').apply(lambda df: calc_f1_score(df['true'],df['pred']))\n",
    "state_val_f1 = val_pred_df.groupby('state').apply(lambda df: calc_f1_score(df['true'],df['pred']))\n",
    "state_count = playa_att_df.groupby('state').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,3, figsize=[15,8])\n",
    "state_count.plot.bar(ax=ax[0,0], title='Playa Count')\n",
    "state_val_loss.plot.bar(ax=ax[0,1], title='Val Loss')\n",
    "state_val_f1.plot.bar(ax=ax[0,2], title='Val F1')\n",
    "state_test_loss.plot.bar(ax=ax[1,1], title='Test Loss')\n",
    "state_test_f1.plot.bar(ax=ax[1,2], title='Test F1')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By HUC 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huc_test_loss = test_pred_df.groupby('huc4').apply(lambda df: log_loss(df['true'],df['pred'], labels=[0,1]))\n",
    "huc_val_loss = val_pred_df.groupby('huc4').apply(lambda df: log_loss(df['true'],df['pred'], labels=[0,1]))\n",
    "huc_test_f1 = test_pred_df.groupby('huc4').apply(lambda df: calc_f1_score(df['true'],df['pred']))\n",
    "huc_val_f1 = val_pred_df.groupby('huc4').apply(lambda df: calc_f1_score(df['true'],df['pred']))\n",
    "huc_count = playa_att_df.groupby('huc4').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,3, figsize=[15,8])\n",
    "huc_count.plot.bar(ax=ax[0,0], title='HUC4 Playa Count')\n",
    "huc_val_loss.plot.bar(ax=ax[0,1], title='Val Loss')\n",
    "huc_val_f1.plot.bar(ax=ax[0,2], title='Val F1')\n",
    "huc_test_loss.plot.bar(ax=ax[1,1], title='Test Loss')\n",
    "huc_test_f1.plot.bar(ax=ax[1,2], title='Test F1')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By Author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_test_loss = test_pred_df.groupby('author').apply(lambda df: log_loss(df['true'],df['pred'], labels=[0,1]))\n",
    "author_val_loss = val_pred_df.groupby('author').apply(lambda df: log_loss(df['true'],df['pred'], labels=[0,1]))\n",
    "author_test_f1 = test_pred_df.groupby('author').apply(lambda df: calc_f1_score(df['true'],df['pred']))\n",
    "author_val_f1 = val_pred_df.groupby('author').apply(lambda df: calc_f1_score(df['true'],df['pred']))\n",
    "author_count = playa_att_df.groupby('author').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,3, figsize=[15,10])\n",
    "author_count.plot.bar(ax=ax[0,0], title='Author Playa Count', rot=45)\n",
    "author_val_loss.plot.bar(ax=ax[0,1], title='Val Loss', rot=45)\n",
    "author_val_f1.plot.bar(ax=ax[0,2], title='Val F1', rot=45)\n",
    "author_test_loss.plot.bar(ax=ax[1,1], title='Test Loss', rot=45)\n",
    "author_test_f1.plot.bar(ax=ax[1,2], title='Test F1', rot=45)\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "playa_venv",
   "language": "python",
   "name": "playa_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
