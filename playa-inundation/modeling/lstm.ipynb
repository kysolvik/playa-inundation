{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from Robert Guthrie https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html\n",
    "# And: https://machinelearningmastery.com/multivariate-time-series-forecasting-lstms-keras/\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import json\n",
    "import glob\n",
    "import h5py\n",
    "import time\n",
    "\n",
    "np.random.seed(55)\n",
    "torch.manual_seed(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():  \n",
    "    dev = 'cuda'\n",
    "else:  \n",
    "    dev = 'cpu'\n",
    "\n",
    "device = torch.device(dev)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cols = ['precip', 'temp', 'vpd', 'acres', 'winddevyr', 'meanwetfrq', 'cluster',\n",
    "       'healthy', 'farmed', 'hydromod', 'fttoroad', 'sthick2013', 'lcf13',\n",
    "       'lcf11', 'lcf14', 'lcf15', 'lcf2', 'lcf7', 'lcf6', 'lcf1', 'lcf12',\n",
    "       'lcf9', 'lcf16', 'lcf8', 'lcf10', 'lcf3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column selection\n",
    "select_cols = ['precip', 'temp', 'vpd', 'acres',\n",
    "                'cluster','healthy', 'farmed', 'hydromod',\n",
    "               'fttoroad', 'meanwetfrq', 'winddevyr','sthick2013', \n",
    "               'lcf13','lcf11', 'lcf14', 'lcf15', 'lcf2', 'lcf7', 'lcf6', 'lcf1', \n",
    "               'lcf12', 'lcf9', 'lcf16', 'lcf8', 'lcf10', 'lcf3']\n",
    "which_cols_from_hdf = np.isin(all_cols, select_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of playas for modelling\n",
    "num_playas = None # None means all playas will be used\n",
    "\n",
    "# Model params to set\n",
    "binary_cutoff = 0.25 # Predictions treated as 1 if larger than this fraction\n",
    "hidden_dim = 128\n",
    "id_embed_dim = 16\n",
    "huc_embed_dim = 8\n",
    "author_embed_dim = 4\n",
    "num_layers=1\n",
    "learning_rate = 0.01\n",
    "num_epochs = 200\n",
    "lr_gamma = 0.9\n",
    "lr_decay_step_size = 5 \n",
    "lr_decay_stop_epoch = 50\n",
    "# 2e-6 was best yet\n",
    "regularization_weight = 2.5e-6 \n",
    "batch_size = 64\n",
    "\n",
    "early_stopping=16 \n",
    "\n",
    "# These are hard coded, the torch embedding layers need to know the max value they can expect\n",
    "max_id = 71852\n",
    "max_author = 4\n",
    "max_huc = 140\n",
    "lstm_input_size = len(select_cols)\n",
    "\n",
    "# Hard-coded input hdf file:\n",
    "hdf_path = '/data/all_prepped_data.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Up Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(hdf_path, 'r')\n",
    "\n",
    "# Get some params for reshaping\n",
    "n_playas, train_seq_len = f['train_num'].shape[:2]\n",
    "val_seq_len = f['val_num'].shape[1]\n",
    "\n",
    "# Load data and run scaler simultaneously, requires some reshaping to 2d and back to 3d\n",
    "scaler = StandardScaler()\n",
    "train_num = scaler.fit_transform(\n",
    "    f['train_num'][()][:,:,which_cols_from_hdf].reshape(\n",
    "        [n_playas*train_seq_len, lstm_input_size])\n",
    "    ).reshape([n_playas, train_seq_len, lstm_input_size])\n",
    "train_cat = f['train_cat'][()].astype(int)\n",
    "train_y = f['train_y'][()]\n",
    "val_num = scaler.transform(\n",
    "    f['val_num'][()][:,:,which_cols_from_hdf].reshape(\n",
    "        [n_playas*val_seq_len, lstm_input_size])\n",
    "    ).reshape([n_playas, val_seq_len, lstm_input_size])\n",
    "val_cat = f['val_cat'][()].astype(int)\n",
    "val_y = f['val_y'][()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_ds = torch.utils.data.TensorDataset(\n",
    "    torch.Tensor(train_num), torch.Tensor(train_cat).long(), torch.Tensor(train_y),\n",
    "    torch.Tensor(val_num), torch.Tensor(val_cat).long(), torch.Tensor(val_y))\n",
    "train_val_loader = torch.utils.data.DataLoader(\n",
    "    train_val_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we define our model as a class\n",
    "class LSTM(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_dim, hidden_dim, num_layers, output_dim,\n",
    "                 id_embed_dim, max_id, huc_embed_dim, max_huc, author_embed_dim, max_author,\n",
    "                 device):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        self.id_embed_dim = id_embed_dim\n",
    "        self.max_id = max_id\n",
    "        self.huc_embed_dim = huc_embed_dim\n",
    "        self.max_huc = max_huc\n",
    "        self.author_embed_dim = author_embed_dim\n",
    "        self.max_author = max_author\n",
    "        \n",
    "        self.full_input_dim = self.input_dim + self.id_embed_dim + self.huc_embed_dim + self.author_embed_dim\n",
    "        \n",
    "        self.device = device\n",
    "        \n",
    "        # Define embedding layers\n",
    "        self.id_embedding = nn.Embedding(self.max_id+1, self.id_embed_dim).to(self.device)\n",
    "        self.huc_embedding = nn.Embedding(self.max_huc+1, self.huc_embed_dim).to(self.device)\n",
    "        self.author_embedding = nn.Embedding(self.max_author+1, self.author_embed_dim).to(self.device)\n",
    "\n",
    "        # Define the LSTM layer\n",
    "        self.lstm = nn.LSTM(self.full_input_dim, self.hidden_dim, self.num_layers, batch_first=True).to(self.device)\n",
    "\n",
    "        # Define activations for output\n",
    "        self.linear = nn.Linear(self.hidden_dim, output_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        self.h = torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(self.device)\n",
    "        self.c = torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(self.device)\n",
    "        return\n",
    "\n",
    "    \n",
    "    def forward(self, input_numeric, playa_ids, hucs, auths):\n",
    "        # Forward pass through LSTM layer\n",
    "        # shape of input: [batch_size, timesteps, input_dims]\n",
    "        # shape of lstm_out: [batch_size, timesteps, hidden_dim]\n",
    "        # shape of self.hidden: (a, b), where a and b both \n",
    "        # have shape (num_layers, batch_size, hidden_dim).\n",
    "        # Shape of y_pred: [batch_size, timesteps, 4]\n",
    "        # Run ids through embedding layer        \n",
    "        # Concat and run through LSTM\n",
    "        \n",
    "        \n",
    "        # Check that hidden layers have expected shape\n",
    "        assert self.h.shape == torch.Size([self.num_layers, input_numeric.size(0), self.hidden_dim])\n",
    "        assert self.c.shape == torch.Size([self.num_layers, input_numeric.size(0), self.hidden_dim])\n",
    "\n",
    "        # Run categorical data through embeddings\n",
    "        self.id_emb= self.id_embedding(playa_ids.to(self.device))\n",
    "        self.huc_emb= self.huc_embedding(hucs.to(self.device))\n",
    "        self.author_emb= self.author_embedding(auths.to(self.device))\n",
    "\n",
    "\n",
    "        # Concat embedding and inputs and run through LSTM\n",
    "        lstm_out, (self.h, self.c) = self.lstm(\n",
    "            torch.cat((input_numeric, self.id_emb, self.huc_emb, self.author_emb), 2),\n",
    "            (self.h, self.c)\n",
    "        )\n",
    "        \n",
    "        # Assert that shapes are still as expected\n",
    "        assert self.h.shape == torch.Size([self.num_layers, input_numeric.size(0), self.hidden_dim])\n",
    "        assert self.c.shape == torch.Size([self.num_layers, input_numeric.size(0), self.hidden_dim])\n",
    "        assert lstm_out.shape == torch.Size([input_numeric.size(0), input_numeric.size(1), self.hidden_dim]) # batch, seq_len, hidden\n",
    "\n",
    "        \n",
    "        # Run activation and get outputs\n",
    "        lin_act = self.linear(lstm_out)\n",
    "        y_pred = self.sigmoid(lin_act) \n",
    "\n",
    "        # Check that outputs are expected shape [batch_size, seq_len, 1]\n",
    "        assert lin_act.shape == torch.Size([input_numeric.size(0), input_numeric.size(1), 1])\n",
    "        assert lin_act.shape == y_pred.shape\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "model = LSTM(input_dim = lstm_input_size,\n",
    "             hidden_dim=hidden_dim,\n",
    "             num_layers=num_layers,\n",
    "             output_dim=1,\n",
    "             id_embed_dim = id_embed_dim,\n",
    "             max_id = max_id,\n",
    "             huc_embed_dim = huc_embed_dim,\n",
    "             max_huc = max_huc,\n",
    "             author_embed_dim = author_embed_dim,\n",
    "             max_author = max_author,\n",
    "             device=device)\n",
    "\n",
    "if dev == 'cuda':\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bceloss = torch.nn.BCELoss()   \n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=regularization_weight)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimiser, step_size=lr_decay_step_size, gamma=lr_gamma)\n",
    "#####################---------------------------------------------------------------------------\n",
    "# Train model\n",
    "#####################\n",
    "\n",
    "loss_history = []\n",
    "val_loss_history = []\n",
    "\n",
    "best_loss = 1000\n",
    "i=0\n",
    "start = time.time()\n",
    "for t in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "    val_epoch_loss = 0\n",
    "    total_items = 0\n",
    "    val_total_items = 0\n",
    "    # Lists to store all predictions and all ordered groundtruth\n",
    "    cur_train_y_ordered = []\n",
    "    cur_val_y_ordered = []\n",
    "    all_train_pred = []\n",
    "    all_val_pred = []\n",
    "    for x_batch, cat_batch, y_batch, val_x_batch, val_cat_batch, val_y_batch in train_val_loader: \n",
    "        x_batch = x_batch.to(device)\n",
    "        cat_batch = cat_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        val_x_batch = val_x_batch.to(device)\n",
    "        val_cat_batch = val_cat_batch.to(device)\n",
    "        val_y_batch = val_y_batch.to(device)\n",
    "            \n",
    "        # Get groundtruth in shuffle order\n",
    "        cur_train_y_ordered.append(y_batch.view(-1).detach())\n",
    "        cur_val_y_ordered.append(val_y_batch.view(-1).detach())\n",
    "                \n",
    "                \n",
    "        # Clear stored gradient\n",
    "        optimiser.zero_grad()\n",
    "        \n",
    "        # Init hidden state\n",
    "        model.init_hidden(batch_size=x_batch.size(0))\n",
    "        \n",
    "        # Training: Predict and calc loss\n",
    "        train_pred = model(x_batch, cat_batch[:,:,0], cat_batch[:,:,1], cat_batch[:,:,2])\n",
    "        \n",
    "        loss = bceloss(\n",
    "            train_pred[:,:,0],\n",
    "            y_batch \n",
    "        )\n",
    "        \n",
    "        all_train_pred.append(train_pred.view(-1).detach())\n",
    "\n",
    "        # Tracking mean loss across batches\n",
    "        epoch_loss += train_pred.shape[0]*loss.item()\n",
    "        total_items += train_pred.shape[0]\n",
    "\n",
    "        \n",
    "        # Validation: predict and calc loss\n",
    "        val_pred = model(val_x_batch, val_cat_batch[:,:,0], val_cat_batch[:,:,1], val_cat_batch[:,:,2])\n",
    "\n",
    "        val_loss = bceloss(\n",
    "            val_pred[:,:,0],\n",
    "            val_y_batch\n",
    "        )\n",
    "        all_val_pred.append(val_pred.view(-1).detach())\n",
    "\n",
    "        # Tracking mean loss across batches\n",
    "        val_epoch_loss += val_pred.shape[0]*val_loss.item()\n",
    "        val_total_items += val_pred.shape[0]\n",
    "\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update parameters\n",
    "        optimiser.step()\n",
    "\n",
    "    # LR decay\n",
    "    if t <= lr_decay_stop_epoch:\n",
    "        scheduler.step()\n",
    "    \n",
    "    epoch_loss = epoch_loss/total_items\n",
    "    val_epoch_loss = val_epoch_loss/val_total_items\n",
    "    loss_history.append(epoch_loss)\n",
    "    val_loss_history.append(val_epoch_loss)\n",
    "    if t%1==0:\n",
    "        print(\"Epoch \", t, \"Train Loss: \", epoch_loss, \"Val Loss:\", val_epoch_loss, \"LR: \", optimiser.param_groups[0][\"lr\"])\n",
    "        \n",
    "    if np.isnan(epoch_loss):\n",
    "        break\n",
    "        \n",
    "    # Early stopping\n",
    "    if val_epoch_loss < best_loss:\n",
    "        i = 0\n",
    "        # Save best loss, predictoins, and hidden state\n",
    "        best_loss = val_epoch_loss\n",
    "        best_train_pred = torch.cat(all_train_pred, dim=0).cpu().detach().numpy()\n",
    "        best_val_pred = torch.cat(all_val_pred, dim=0).cpu().detach().numpy()\n",
    "        # Save ordered ground truth\n",
    "        train_y_ordered = torch.cat(cur_train_y_ordered).cpu().detach().numpy()\n",
    "        val_y_ordered = torch.cat(cur_val_y_ordered).cpu().detach().numpy()\n",
    "    else:\n",
    "        i+=1\n",
    "    if (i > early_stopping):\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# View results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_loss)\n",
    "plt.plot(loss_history)\n",
    "plt.show()\n",
    "plt.plot(val_loss_history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = [37900, 38000]\n",
    "pd.DataFrame({'Pred':best_train_pred[window[0]:window[1]], 'True':train_y_ordered[window[0]:window[1]]}).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_tp = ((train_y_ordered>0.5)*(best_train_pred>binary_cutoff)).sum()\n",
    "trn_fp = ((train_y_ordered<0.5)*(best_train_pred>binary_cutoff)).sum()\n",
    "trn_tn = ((train_y_ordered<0.5)*(best_train_pred<binary_cutoff)).sum()\n",
    "trn_fn = ((train_y_ordered>0.5)*(best_train_pred<binary_cutoff)).sum()\n",
    "\n",
    "print('True pos: ',trn_tp)\n",
    "print('False pos: ',trn_fp)\n",
    "print('True neg: ', trn_tn)\n",
    "print('False neg: ', trn_fn)\n",
    "\n",
    "# Prec, recall, f1\n",
    "trn_prec = trn_tp / (trn_tp + trn_fp)\n",
    "trn_recall = trn_tp / (trn_tp + trn_fn)\n",
    "print('Prec: ', trn_prec)\n",
    "print('Recall: ', trn_recall)\n",
    "print('F1: ', 2*(trn_prec*trn_recall)/(trn_prec + trn_recall))\n",
    "\n",
    "\n",
    "# ROC curve\n",
    "fpr, tpr, thresholds = sklearn.metrics.roc_curve(train_y_ordered, best_train_pred, pos_label=1)\n",
    "print('AUC: ', sklearn.metrics.auc(fpr, tpr))\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Pos Rate')\n",
    "plt.ylabel('True Pos Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = [30900, 31000]\n",
    "pd.DataFrame({'Pred':best_val_pred[window[0]:window[1]], 'True':val_y_ordered[window[0]:window[1]]}).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_tp = ((val_y_ordered>0.5)*(best_val_pred>binary_cutoff)).sum()\n",
    "val_fp = ((val_y_ordered<0.5)*(best_val_pred>binary_cutoff)).sum()\n",
    "val_tn = ((val_y_ordered<0.5)*(best_val_pred<binary_cutoff)).sum()\n",
    "val_fn = ((val_y_ordered>0.5)*(best_val_pred<binary_cutoff)).sum()\n",
    "\n",
    "print('True pos: ',val_tp)\n",
    "print('False pos: ',val_fp)\n",
    "print('True neg: ', val_tn)\n",
    "print('False neg: ', val_fn)\n",
    "\n",
    "# Prec, recall, f1\n",
    "val_prec = val_tp / (val_tp + val_fp)\n",
    "val_recall = val_tp / (val_tp + val_fn)\n",
    "print('Prec: ', val_prec)\n",
    "print('Recall: ', val_recall)\n",
    "print('F1: ', 2*(val_prec*val_recall)/(val_prec + val_recall))\n",
    "\n",
    "# ROC curve\n",
    "fpr, tpr, thresholds = sklearn.metrics.roc_curve(val_y_ordered, best_val_pred, pos_label=1)\n",
    "\n",
    "print('AUC: ', sklearn.metrics.auc(fpr, tpr))\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Pos Rate')\n",
    "plt.ylabel('True Pos Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%bash \n",
    "# sudo shutdown -h now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_latest_p36)",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
