{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bb91ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from Robert Guthrie https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html\n",
    "# And: https://machinelearningmastery.com/multivariate-time-series-forecasting-lstms-keras/\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import json\n",
    "import glob\n",
    "import h5py\n",
    "import time\n",
    "\n",
    "np.random.seed(55)\n",
    "torch.manual_seed(25)\n",
    "from temperature_scaling import ModelWithTemperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1830d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():  \n",
    "    dev = 'cuda'\n",
    "else:  \n",
    "    dev = 'cpu'\n",
    "\n",
    "device = torch.device(dev)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fb2eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cols = ['precip', 'temp', 'vpd', 'acres', 'winddevyr', 'meanwetfrq', 'cluster',\n",
    "       'healthy', 'farmed', 'hydromod', 'fttoroad', 'sthick2013', 'lcf13',\n",
    "       'lcf11', 'lcf14', 'lcf15', 'lcf2', 'lcf7', 'lcf6', 'lcf1', 'lcf12',\n",
    "       'lcf9', 'lcf16', 'lcf8', 'lcf10', 'lcf3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbfc8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column selection\n",
    "select_cols = ['precip', 'temp', 'vpd', 'acres',\n",
    "                'cluster','healthy', 'farmed', 'hydromod',\n",
    "               'fttoroad', 'meanwetfrq', 'sthick2013', # 'winddevyr',\n",
    "               'lcf13','lcf11', 'lcf14', 'lcf15', 'lcf2', 'lcf7', 'lcf6', 'lcf1', \n",
    "               'lcf12', 'lcf9', 'lcf16', 'lcf8', 'lcf10', 'lcf3']\n",
    "which_cols_from_hdf = np.isin(all_cols, select_cols)\n",
    "\n",
    "# Output model dict path:\n",
    "model_path = './model_weights.pytorch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e12ca1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of playas for modelling\n",
    "num_playas = None # None means all playas will be used\n",
    "\n",
    "hidden_dim = 128\n",
    "id_embed_dim = 16\n",
    "huc_embed_dim = 8\n",
    "author_embed_dim = 4\n",
    "num_layers=1\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "early_stopping=16 \n",
    "\n",
    "# Input hdf file, have it set to direct mounted ssd on AWS EC2 but can be changed\n",
    "hdf_path = '/data/all_prepped_data.h5'\n",
    "\n",
    "# These are hard coded, the torch embedding layers need to know the max value they can expect\n",
    "max_id = 71852\n",
    "max_author = 4\n",
    "max_huc = 140\n",
    "lstm_input_size = len(select_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6917ab",
   "metadata": {},
   "source": [
    "# Set Up Dataloader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91069b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(hdf_path, 'r')\n",
    "\n",
    "# Get some params for reshaping\n",
    "n_playas, train_seq_len = f['train_num'].shape[:2]\n",
    "val_seq_len = f['val_num'].shape[1]\n",
    "test_seq_len =  f['test_num'].shape[1]\n",
    "\n",
    "# Load data and run scaler simultaneously, requires some reshaping to 2d and back to 3d\n",
    "scaler = StandardScaler()\n",
    "train_num = scaler.fit_transform(\n",
    "    f['train_num'][()][:,:,which_cols_from_hdf].reshape(\n",
    "        [n_playas*train_seq_len, lstm_input_size])\n",
    "    ).reshape([n_playas, train_seq_len, lstm_input_size])\n",
    "train_cat = f['train_cat'][()].astype(int)\n",
    "train_y = f['train_y'][()]\n",
    "val_num = scaler.transform(\n",
    "    f['val_num'][()][:,:,which_cols_from_hdf].reshape(\n",
    "        [n_playas*val_seq_len, lstm_input_size])\n",
    "    ).reshape([n_playas, val_seq_len, lstm_input_size])\n",
    "val_cat = f['val_cat'][()].astype(int)\n",
    "val_y = f['val_y'][()]\n",
    "test_num = scaler.transform(\n",
    "    f['test_num'][()][:,:,which_cols_from_hdf].reshape(\n",
    "        [n_playas*test_seq_len, lstm_input_size])\n",
    "    ).reshape([n_playas, test_seq_len, lstm_input_size])\n",
    "test_cat = f['test_cat'][()].astype(int)\n",
    "test_y = f['test_y'][()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ae35f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_test_ds = torch.utils.data.TensorDataset(\n",
    "    torch.Tensor(train_num), torch.Tensor(train_cat).long(), torch.Tensor(train_y),\n",
    "    torch.Tensor(val_num), torch.Tensor(val_cat).long(), torch.Tensor(val_y),\n",
    "    torch.Tensor(test_num), torch.Tensor(test_cat).long(), torch.Tensor(test_y)\n",
    "    )\n",
    "train_val_test_loader = torch.utils.data.DataLoader(\n",
    "    train_val_test_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085c2289",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_model = ... # create an uncalibrated model somehow\n",
    "valid_loader = ... # Create a DataLoader from the SAME VALIDATION SET used to train orig_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4aa4387",
   "metadata": {},
   "source": [
    "### Model calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7bd78c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_latest_p36_playa)",
   "language": "python",
   "name": "conda_pytorch_latest_p36_playa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
