{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from Robert Guthrie https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html\n",
    "# And: https://machinelearningmastery.com/multivariate-time-series-forecasting-lstms-keras/\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import json\n",
    "import glob\n",
    "import h5py\n",
    "import time\n",
    "\n",
    "np.random.seed(55)\n",
    "torch.manual_seed(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():  \n",
    "    dev = 'cuda'\n",
    "else:  \n",
    "    dev = 'cpu'\n",
    "\n",
    "device = torch.device(dev)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cols = ['precip', 'temp', 'vpd', 'acres', 'winddevyr', 'meanwetfrq', 'cluster',\n",
    "       'healthy', 'farmed', 'hydromod', 'fttoroad', 'sthick2013', 'mean_inun','lcf13',\n",
    "       'lcf11', 'lcf14', 'lcf15', 'lcf2', 'lcf7', 'lcf6', 'lcf1', 'lcf12',\n",
    "       'lcf9', 'lcf16', 'lcf8', 'lcf10', 'lcf3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column selection\n",
    "select_cols = ['precip', 'temp', 'vpd', 'acres',\n",
    "                'cluster','healthy', 'farmed', 'hydromod',\n",
    "               'fttoroad',  'sthick2013', 'mean_inun', #'meanwetfrq', 'winddevyr', \n",
    "               'lcf13','lcf11', 'lcf14', 'lcf15', 'lcf2', 'lcf7', 'lcf6', 'lcf1', \n",
    "               'lcf12', 'lcf9', 'lcf16', 'lcf8', 'lcf10', 'lcf3']\n",
    "which_cols_from_hdf = np.isin(all_cols, select_cols)\n",
    "\n",
    "# Output model dict path:\n",
    "model_path = './model_weights_earlyshift_morereg.pytorch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of playas for modelling\n",
    "num_playas = None # None means all playas will be used\n",
    "\n",
    "hidden_dim = 128\n",
    "id_embed_dim = 16\n",
    "huc_embed_dim = 8\n",
    "author_embed_dim = 4\n",
    "num_layers=1\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "early_stopping=16 \n",
    "\n",
    "# Input hdf file, have it set to direct mounted ssd on AWS EC2 but can be changed\n",
    "hdf_path = '../data/all_prepped_data_earlyshift.h5'\n",
    "\n",
    "# These are hard coded, the torch embedding layers need to know the max value they can expect\n",
    "max_id = 71852\n",
    "max_author = 4\n",
    "max_huc = 140\n",
    "lstm_input_size = len(select_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Up Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(hdf_path, 'r')\n",
    "\n",
    "# Get some params for reshaping\n",
    "n_playas, train_seq_len = f['train_num'].shape[:2]\n",
    "val_seq_len = f['val_num'].shape[1]\n",
    "test_seq_len =  f['test_num'].shape[1]\n",
    "\n",
    "# Load data and run scaler simultaneously, requires some reshaping to 2d and back to 3d\n",
    "scaler = StandardScaler()\n",
    "train_num = scaler.fit_transform(\n",
    "    f['train_num'][()][:,:,which_cols_from_hdf].reshape(\n",
    "        [n_playas*train_seq_len, lstm_input_size])\n",
    "    ).reshape([n_playas, train_seq_len, lstm_input_size])\n",
    "train_cat = f['train_cat'][()].astype(int)\n",
    "train_y = f['train_y'][()]\n",
    "val_num = scaler.transform(\n",
    "    f['val_num'][()][:,:,which_cols_from_hdf].reshape(\n",
    "        [n_playas*val_seq_len, lstm_input_size])\n",
    "    ).reshape([n_playas, val_seq_len, lstm_input_size])\n",
    "val_cat = f['val_cat'][()].astype(int)\n",
    "val_y = f['val_y'][()]\n",
    "test_num = scaler.transform(\n",
    "    f['test_num'][()][:,:,which_cols_from_hdf].reshape(\n",
    "        [n_playas*test_seq_len, lstm_input_size])\n",
    "    ).reshape([n_playas, test_seq_len, lstm_input_size])\n",
    "test_cat = f['test_cat'][()].astype(int)\n",
    "test_y = f['test_y'][()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_test_ds = torch.utils.data.TensorDataset(\n",
    "    torch.Tensor(train_num), torch.Tensor(train_cat).long(), torch.Tensor(train_y),\n",
    "    torch.Tensor(val_num), torch.Tensor(val_cat).long(), torch.Tensor(val_y),\n",
    "    torch.Tensor(test_num), torch.Tensor(test_cat).long(), torch.Tensor(test_y)\n",
    "    )\n",
    "train_val_test_loader = torch.utils.data.DataLoader(\n",
    "    train_val_test_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we define our model as a class\n",
    "class LSTM(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_dim, hidden_dim, num_layers, output_dim,\n",
    "                 id_embed_dim, max_id, huc_embed_dim, max_huc, author_embed_dim, max_author,\n",
    "                 device):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        self.id_embed_dim = id_embed_dim\n",
    "        self.max_id = max_id\n",
    "        self.huc_embed_dim = huc_embed_dim\n",
    "        self.max_huc = max_huc\n",
    "        self.author_embed_dim = author_embed_dim\n",
    "        self.max_author = max_author\n",
    "        \n",
    "        self.full_input_dim = self.input_dim + self.id_embed_dim + self.huc_embed_dim + self.author_embed_dim\n",
    "        \n",
    "        self.device = device\n",
    "        \n",
    "        # Define embedding layers\n",
    "        self.id_embedding = nn.Embedding(self.max_id+1, self.id_embed_dim).to(self.device)\n",
    "        self.huc_embedding = nn.Embedding(self.max_huc+1, self.huc_embed_dim).to(self.device)\n",
    "        self.author_embedding = nn.Embedding(self.max_author+1, self.author_embed_dim).to(self.device)\n",
    "\n",
    "        # Define the LSTM layer\n",
    "        self.lstm = nn.LSTM(self.full_input_dim, self.hidden_dim, self.num_layers, batch_first=True).to(self.device)\n",
    "\n",
    "        # Define activations for output\n",
    "        self.linear = nn.Linear(self.hidden_dim, output_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        self.h = torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(self.device)\n",
    "        self.c = torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(self.device)\n",
    "        return\n",
    "\n",
    "    \n",
    "    def forward(self, input_numeric, playa_ids, hucs, auths):\n",
    "        # Forward pass through LSTM layer\n",
    "        # shape of input: [batch_size, timesteps, input_dims]\n",
    "        # shape of lstm_out: [batch_size, timesteps, hidden_dim]\n",
    "        # shape of self.hidden: (a, b), where a and b both \n",
    "        # have shape (num_layers, batch_size, hidden_dim).\n",
    "        # Shape of y_pred: [batch_size, timesteps, 4]\n",
    "        # Run ids through embedding layer        \n",
    "        # Concat and run through LSTM\n",
    "        \n",
    "        \n",
    "        # Check that hidden layers have expected shape\n",
    "        assert self.h.shape == torch.Size([self.num_layers, input_numeric.size(0), self.hidden_dim])\n",
    "        assert self.c.shape == torch.Size([self.num_layers, input_numeric.size(0), self.hidden_dim])\n",
    "\n",
    "        # Run categorical data through embeddings\n",
    "        self.id_emb= self.id_embedding(playa_ids.to(self.device))\n",
    "        self.huc_emb= self.huc_embedding(hucs.to(self.device))\n",
    "        self.author_emb= self.author_embedding(auths.to(self.device))\n",
    "\n",
    "\n",
    "        # Concat embedding and inputs and run through LSTM\n",
    "        lstm_out, (self.h, self.c) = self.lstm(\n",
    "            torch.cat((input_numeric, self.id_emb, self.huc_emb, self.author_emb), 2),\n",
    "            (self.h, self.c)\n",
    "        )\n",
    "        \n",
    "        # Assert that shapes are still as expected\n",
    "        assert self.h.shape == torch.Size([self.num_layers, input_numeric.size(0), self.hidden_dim])\n",
    "        assert self.c.shape == torch.Size([self.num_layers, input_numeric.size(0), self.hidden_dim])\n",
    "        assert lstm_out.shape == torch.Size([input_numeric.size(0), input_numeric.size(1), self.hidden_dim]) # batch, seq_len, hidden\n",
    "\n",
    "        \n",
    "        # Run activation and get outputs\n",
    "        lin_act = self.linear(lstm_out)\n",
    "        y_pred = self.sigmoid(lin_act) \n",
    "\n",
    "        # Check that outputs are expected shape [batch_size, seq_len, 1]\n",
    "        assert lin_act.shape == torch.Size([input_numeric.size(0), input_numeric.size(1), 1])\n",
    "        assert lin_act.shape == y_pred.shape\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "model = LSTM(input_dim = lstm_input_size,\n",
    "             hidden_dim=hidden_dim,\n",
    "             num_layers=num_layers,\n",
    "             output_dim=1,\n",
    "             id_embed_dim = id_embed_dim,\n",
    "             max_id = max_id,\n",
    "             huc_embed_dim = huc_embed_dim,\n",
    "             max_huc = max_huc,\n",
    "             author_embed_dim = author_embed_dim,\n",
    "             max_author = max_author,\n",
    "             device=device)\n",
    "\n",
    "if dev == 'cuda':\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bceloss = torch.nn.BCELoss()   \n",
    "\n",
    "#####################---------------------------------------------------------------------------\n",
    "# Run model\n",
    "#####################\n",
    "y_ordered = []\n",
    "all_pred = []\n",
    "all_cats_list = []\n",
    "for (x_batch, cat_batch, y_batch,\n",
    "     val_x_batch, val_cat_batch, val_y_batch,\n",
    "     test_x_batch, test_cat_batch, test_y_batch) in train_val_test_loader: \n",
    "    all_x_batch = torch.cat([x_batch, val_x_batch, test_x_batch], 1).to(device)\n",
    "    all_cat_batch = torch.cat([cat_batch, val_cat_batch, test_cat_batch], 1).to(device)\n",
    "    all_y_batch = torch.cat([y_batch, val_y_batch, test_y_batch],1).to(device)\n",
    "            \n",
    "    # Get groundtruth in shuffle order\n",
    "    y_ordered.append(all_y_batch.view(-1).detach())\n",
    "    \n",
    "    # Get categorical variables to help with analysis\n",
    "    all_cats_list.append(all_cat_batch.view(-1, 3).detach())\n",
    "\n",
    "    model.init_hidden(batch_size=x_batch.size(0))\n",
    "\n",
    "    # Training: Predict and calc loss\n",
    "    pred = model(all_x_batch, all_cat_batch[:,:,0], all_cat_batch[:,:,1], all_cat_batch[:,:,2])\n",
    "        \n",
    "    all_pred.append(pred.view(-1).detach())\n",
    "    \n",
    "        \n",
    "best_pred = torch.cat(all_pred, dim=0).cpu().detach().numpy()\n",
    "# Save ordered ground truth\n",
    "y_ordered = torch.cat(y_ordered).cpu().detach().numpy()\n",
    "\n",
    "all_cats = torch.cat(all_cats_list).cpu().detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bceloss(torch.tensor(best_pred), torch.tensor(y_ordered))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame({\n",
    "    'true':y_ordered.astype(np.int8),\n",
    "    'pred':best_pred,\n",
    "    'id':all_cats[:,0].astype(np.uint32),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.to_csv('./all_preds_earlyshift_morereg.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_latest_p36_playa)",
   "language": "python",
   "name": "conda_pytorch_latest_p36_playa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
